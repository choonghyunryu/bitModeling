---
title: "Introduce tidymodels"
author: "Choonghyun Ryu"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduce tidymodels}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r environment, echo = FALSE, message = FALSE, warning=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "", out.width = "600px", dpi = 70)
options(tibble.print_min = 4L, tibble.print_max = 4L)

library(bitmodeling)
library(dplyr)
library(ggplot2)
```

## tidymodels

tidymodels 프레임워크는 tidyverse의 주요 기능을 계승한, Machine Learning을 위한 패키지들의 모음입니다. 이 프레임워크를 사용하면 모델을 개발하고 평가하는 일련의 작업을 마치 물 흐르듯 Seamless하게 처리할 수 있습니다. 

### Machine Learning 프로세스와 tidymodels

Machine Learning의 과정을 일반화하면 다음과 같이 순차적으로 분류할 수 있습니다. 그리고 각각의 과정을 지원하는 tidymodels 프레임워크의 패키지들이 있습니다.

1. Data Resampling과 Feature Engineering
    - rsample, recipes
2. Model Fitting과 Tuning
    - parsnip, tune, dials
3. Model Evaluation
    - yardstick

    
좀더 쉽게 이해하기 위해서, 일반화한 `Machine Learning`의 과정을 프로세스로 시각화하면 다음과 같습니다. 

- 순차적인 `Data Resampling`과 `Feature Engineering`의 흐름 뒤에는
- Closed-Loop 관점에서, 성능이 만족할 수준까지의 `Model Fitting`과 `Model Tuning`, `Model Evaluation` 과정이  반복적으로 수행됩니다.


```{r fig1, echo=FALSE, out.width = "95%", fig.align='center'}
knitr::include_graphics("img/tidymodel_eco.jpg")
```


### 대표적인 tidymodels 패키지

tidymodes 생태계에는 더 많은 패키지가 있지만, 본 소개에서는 다음 패키지에 중점을 둘 것입니다.

<br>

```{r fig3, echo=FALSE, out.width = "95%", fig.align='center'}
knitr::include_graphics("img/big_picture.png")
```

<br>

- rsample
    - 데이터를 학습과 테스트 세트로 분할(교차검증도 포함)
- recipes
    - 전처리로 데이터 준비
- parsnip
    - 데이터에 모델 적합 정의
- yardstick, tune
    - 모델의 성능 평가
- workflows
    - recipes와 parsnip 개체를 워크플로우로 결합
    - 수행한 작업을 좀 더 쉽게 추적하고, 특정 단계를 쉽게 수정이 가능함
- tune, dials
    - 모델 최적화, hyper-parameters 튜닝 등.
- broom
    - 모델 적합 결과를 쉽게 해석

<br>


### tidyverse 패키지와 tidymodels 패키지

`Machine Learning`을 수행하는 과정에서 이러한 tidymodels 패키지군이 작동하는 방법을 좀더 구체화하면 다음 시각화와 같습니다. 

<br>

```{r fig4, echo=FALSE, out.width = "95%", fig.align='center'}
knitr::include_graphics("img/process.png")
```

<br>

이즈음에서 우리는 tidyverse의 파이프처리 방법을 떠올려야 합니다. 

현재 태스크의 결과가 다음 태스크의 정보로 사용되는 일련의 작업을 함수로 치환한다면,
현재 작업을 위한 함수의 연산으로 Output된 결과가 다음 작업을 위한 함수의 Input으로 사용된다는 점입니다.

이러한 작업이 파이프 연산자로 묶여서 Seamless하게 처리됩니다. 다음의 dplyr 구문을 보십시요.:

```{r, eval=FALSE}
flights %>% 
  group_by(month, day) %>% 
  summarise(dep_delay_avg = mean(dep_delay, na.rm = TRUE),
            .groups = "drop") %>% 
  arrange(desc(dep_delay_avg)) %>% 
  filter(row_number() <= 5)
```

이 표현식은 다음의 작업을 순차적으로 실행합니다.

1. flights 데이터를 읽어서,
2. month와 day 변수를 그룹핑지어서,
3. dep_delay 변수의 산술평균을 계산하여 dep_delay_avg 변수로 만들고,
4. dep_delay_avg를 내림차순으로 정렬한 후,
5. 상위 5건만 취한다.

이와 같은 순차적인 작업의 프로세스에서 중요한 것은 개별 작업을 수행하는 함수가 제공되어야 한다는 점입니다.

일련의 작업을 물 흐르듯 수행하기 위해서는 파이프라인을 설계할 수 있는 여러 종류(스팩)의 개별 파이프가 필요한 것입니다. 그래야 파이프 배관공이 파이프를 연결하여 원하는 곳에 물이나 석유 등을 옮겨올 수 있기 때문입니다.

tidymodels에서 제공하는 파이프의 스팩과 파이프는 다음과 같습니다. `Spec`이 파이프의 스팩이고 `Function`이 스팩의 기능을 만족하는 파이프들입니다.

이제 여러분은 파이프 배관공이 되어서 tidymodels에서 제공하는 파이프들을 연결해서 `Machine Learning`이라는 배관작업을 수행해야 합니다.

<br>

```{r fig5, echo=FALSE, out.width = "95%", fig.align='center'}
knitr::include_graphics("img/overview.png")
```

<br>


## Binary Classification

`dlookr::heartfailure`는 심혈관 질환의 하나인 심부전으로 인한 사망을 예측하는데 사용할 수 있는 심부전 환자의 데이터셋입니다.  299건의 관측치와 다음과 같은 13개의 변수로 구성되어 있습니다.

- age
    - 환자의 나이
- anaemia
    - 변혈 여부. 적혈구 또는 헤모글로빈 감소
    - Yes/No  
- cpk_enzyme
    - 혈중 CPK(creatinine phosphokinase) 효소의 수치 (mcg/L).
- diabetes
    - 당뇨병 여부
    - Yes/No      
- ejection_fraction
    - 수축치 심장에서 나가는 혈액의 비율 (백분율)
- hblood_pressure
    - 고혈압 여부
    - Yes/No     
- platelets
    - 혈액내 혈소판 수 (1,000/mL).
- creatinine
    - 혈중 크레아티닌 수치 (mg/dL).
- sodium
    - 혈중 나트륨 수치 (mEq/L).
- sex
    - 환자의 성별
    - Male/Female
- smoking
    - 흡연 여부
    - Yes/No       
- time
    - 후속 조치 기간 (일)
- death_event
    - 추적 기간동안의 환자의 사망여부
    - Yes/No 

tidymodels 패키지를 이용해서, `dlookr::heartfailure`로 심부전 환자에 대한 사망 여부를 예측하는 Binary Classification 모델을 개발할 것입니다.


### Data resampling

ML의 시작은 모델을 작성하기 위한 훈련 데이터와 모델을 평가하기 위한 테스트 데이터를 만드는 것으로 시작합니다.
테스트 데이터는 신규 데이터에서 모델이 수행될 때의 추정치를 제공하고, 과적합을 방지하는 데 도움을 줍니다.

tidymodels 패키지군의 `rsample` 패키지의 `initial_split()`, `training()`, `testing()` 함수가 데이터셋을 split하는 작업을 수행합니다.

```{r, eval=TRUE, message=FALSE}
library(tidymodels)

set.seed(123)
# Create the data split object
heartfailure_split <- dlookr::heartfailure %>% 
  mutate(death_event = factor(death_event, levels = c("Yes", "No"))) %>% 
  initial_split(prop = 0.7, strata = death_event) 

# Create the training data
heartfailure_train <- training(heartfailure_split)

# Create the test data
heartfailure_test  <- testing(heartfailure_split)
```

분리된 두 데이터 셋의 건수를 조회합니다.

```{r, eval=TRUE, message=FALSE}
nrow(heartfailure_train)

nrow(heartfailure_test)
```


### Fit model

로지스틱 회귀분석을 수행하려 합니다. 다음처럼 `parsnip` 패키지의 `logistic_reg()`, `set_engine()`, `set_mode()` 함수로 `glm` 엔진으로 `classification` 모델을 수행하는 로지스틱 회귀분석 스팩을 정의합니다.

```{r}
# Specify a logistic regression model
logistic_model <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

# Print the model specification
logistic_model
```

`fit()` 함수로 로지스틱 회귀분석 모델을 적합합니다.

```{r}
# Fit to training data
logistic_fit <- logistic_model %>% 
  fit(death_event ~ ., data = heartfailure_train)

# Print model fit object
logistic_fit
```


### Predict model

적합한 모델을 평가하기 위해서 검증셋인 `heartfailure_test`에 모델을 적용하여 예측해야 합니다.

#### Predict class

먼저 `death_event`의 범주(클래스)인 `Yes`, `No`를 예측합니다.

```{r}
# Predict outcome category
class_preds <- logistic_fit %>% 
  predict(new_data = heartfailure_test, type = "class")
```


#### Predict probability

그리고 `death_event`의 두 클래스인 `Yes`와 `No`의 확률을 예측합니다.

```{r}
# Predict outcome category
prob_preds <- logistic_fit %>% 
  predict(new_data = heartfailure_test, type = "prob")
```


#### Combine results

실제 `death_event`의 범주, 예측 `death_event` 범주, 예측확률을 묶어서 하나의 데이터셋으로 만듭니다.

```{r}
heartfailure_result <- heartfailure_test %>% 
  select(death_event) %>% 
  bind_cols(class_preds, prob_preds)

head(heartfailure_result)
```

### Evaluate fited model

실제 `death_event`의 범주, 예측 `death_event` 범주, 예측확률로 모델의 성능을 평가합니다.

#### Confusion Matrix

`yardstick` 패키지의 `conf_mat()` 함수로 Confusion Matrix를 구합니다.

```{r}
# Create confusion matrix
cmat <- heartfailure_result %>% 
  conf_mat(truth = death_event, estimate = .pred_class)

# Print confusion matrix object
cmat
```

<br>

`autoplot()` 함수를 이용해서 Confusion Matrix를 히트맵 유형이나 모자이크 플롯 유형으로 시각화할 수 있습니다. 좀더 직관적으로 오불류/정분류를 판독할 수 있습니다.

<br>

```{r, out.width="65%"}
cmat %>% 
  autoplot(type = "heatmap")
```


```{r, out.width="65%"}
cmat %>% 
  autoplot(type = "mosaic")
```

#### Performance metrics

성능평가를 위한 Confusion Matrix 기반의 여러 성능지표를 계산합니다.  앞에서 구한 confusion matrix 객체에 `summary()` 함수만 적용하면 간단하게 계산됩니다.

계산된 13개의 평가 지표는 다음과 같습니다.

- accuracy
    - Accuracy
- kap
    - Kappa
- sens
    - Sensitivity
- spec
    - Specificity    
- ppv
    - Positive predictive value
- npv
    - Negative predictive value    
- mcc
    - Matthews correlation coefficient    
- j_index
    - J-index    
- bal_accuracy
    - Balanced accuracy
- detection_prevalence
    - Detection prevalence    
- precision
    - Precision
- recall
    - Recall
- f_meas
    - F Measure    
    
```{r}
cmat %>% 
  summary() %>% 
  print(n = 15)
```


#### ROC Courve

ROC Courve를 그리기 위해서는 먼저 `roc_curve()`함수로 임계치, specificity, sensitivity를 계산합니다.

```{r}
# Calculate metrics across thresholds
threshold <- heartfailure_result %>% 
  roc_curve(truth = death_event, .pred_Yes)

threshold 
```

그리고 `autoplot()` 함수로 ROC Courve를 그립니다.

```{r, out.width="65%"}
threshold %>% 
  autoplot()
```

##### AUC

AUC(Area under the receiver operator curve)는 `roc_auc()` 함수로 계산합니다.


```{r}
heartfailure_result %>% 
  roc_auc(truth = death_event, .pred_Yes)
```



**어때요? 참 쉽죠?**

```{r, echo=FALSE, out.width = "65%", fig.align='left'}
knitr::include_graphics("img/bob.png")
```

### Recipe

tidimodels는 `Feature engineering`을 위해서 `Recipe`라는 개념을 제공합니다.

일종의 데이터를 모델에 적합하기 위한 최종 구조로 조리하기 위한 조리법이지요.


#### imbalanced 클래스 보정하기

target 변수인 `death_event`의 두 클래스의 비율을 보면 imbalanced 클래스임을 알 수 있습니다. positive 클래스인 `Yes`의 경우에는 32%로 minority 클래스입니다.

```{r}
heartfailure_train %>% 
  count(death_event) %>% 
  mutate(pct = round(n / sum(n) * 100, 2))
```


#### Recipe 정의하기

데이터 조리법(레시피)에 imbalanced 클래스 보정하는 조리 과정을 추가해 봅니다. 
조리 방법은 `recipe` 패키지의 `recipe()` 함수로 정의합니다.

- formula 정의
    - death_event ~ .
    - target 변수에 death_event를 지정하고, predictors에 나머지 모든 변수를 지정합니다.
- imbalanced 클래스 해소
    - `themis` 패키지의 `step_rose()` 함수로 `death_event` 변수의 불균형을 해소합니다.
    - ROSE (Random Over-Sampling Examples) 방법을 적용합니다.

양념을 곁들여서 수치변수에 대해서 표준화(to normalize numeric)를 수행합니다.

- `step_center()` 함수로 표준화 양념 정의
    - all_predictors()
        - 모든 predictors를 대상으로 함
    - -all_nominal()
        - 그러나, 범주형 변수는 대상에서 제거함 

```{r}
# 레시피의 정의
heartfailure_recipe <- recipe(death_event ~ ., data = heartfailure_train) %>% 
  step_center(all_predictors(), -all_nominal()) %>% 
  themis::step_rose(death_event) 

# 레시피의 내용을 살핌
heartfailure_recipe
```

레시피는 레시피일뿐!!!, 레시피 자체로는 데이터 요리가 만들어 지지 않습니다. 레시피 그냥 요리의 순서와 방법을 기술한 내용입니다.

- "명목형 변수를 제외한 모든 predictors를 대상으로 Centering을 통해 표준화를 하세요."
    - "Centering for all_predictors(), -all_nominal()"

#### 요리재료 손질하기

그런데 정의한 래시피는 다분히 추상적인 내용을 담고 있습니다. 다음 조리방법은 모호합니다. "조미료를 적당히 넣어 주세요"와 같은 설명입니다. 쉐프는 어렵지 않겠지만, 조리에 익숙치 않은 사람은 콕찝어 줘야 하겠죠.

`prep()` 함수가 추상적인 레시피를 좀 더 구체화해 줍니다. 

- "age, cpk_enzyme, ejection_fraction, platelets 등의 변수를 Centering을 통해 표준화하세요."
    - Centering for age, cpk_enzyme, ejection_fraction, platelets, ... [trained]

```{r}
heartfailure_recipe %>% 
  prep()
```

다시 생각해봅니다. `prep()` 함수의 이름은 `PREProcessing recipe`에서 따 온 것입니다. 레시지를 전처리한다는 것은 요리 재료를 손질하고 양념들을 준비하는 일종의 준비 작업입니다.

TV의 요리프로에서 대파를 가져와서 흙을 털고, 수염을 자르고 다듬지 않습니다. 깨끗하게 손질한 대파를 준비해 놓지요. 이런 일련의 요리 재료를 준비하고 손질하는 것이 `prep()` 함수의 역할입니다.


그럼 레시피와 레시피에 기술된 재료의 손질 결과가 어떻게 차이나는지 살펴봅니다. 

앞에서 정의한 recipe 객체인 heartfailure_recipe에서 step_center() 작업 정보를 추출합니다.

```{r}
heartfailure_recipe %>% 
  "$"("steps") %>% 
  "[["(1)
```

이번에는 heartfailure_recipe에 `prep()` 함수를 적용한 후의  step_center() 작업 정보를 추출합니다.
**표준화 작업에 사용할 수치 predictors에 대한 산술평균이 계산되어 있습니다.

```{r}
heartfailure_recipe %>% 
  prep() %>% 
  "$"("steps") %>% 
  "[["(1)
```


#### 준비된 재료 조리하기

주스를 만들어 볼까요? `juice()` 함수는 비로소 레시피를 요리하여 한잔의 주스를 만들어 줍니다.
주스를 만들 대상은 `recipe()` 함수로 조리 방법을 정의할 때의 요리 재료로서의 데이터셋, 즉 heartfailure_train입니다. 

그러므로 다음 예제는 training 데이터셋인 heartfailure_train를 요리한 결과로부터 target 변수의 불균형이 해소되었는지 검사하는 작업을 수행합니다. 결과를 보면 불균형이 해소되었습니다.

```{r}
heartfailure_recipe %>% 
  prep() %>% 
  juice() %>% 
  count(death_event) %>% 
  mutate(pct = round(n / sum(n) * 100, 2))  
```

#### 또 다른 재료 조리하기

빵을 구울 수도 있습니다. `bake()` 함수는 레시피를 요리하여 빵을 구워 줍니다. 이 때 대상이되는 재료를 지정할 수 있습니다.
즉 `recipe()` 함수로 조리 방법을 정의할 때 기술한 데이터셋이 아닌 다른 데이터셋을 요리할 수 있습니다. 대체로 test 데이터셋을 요리할 때 사용합니다.

test 데이터셋인 heartfailure_test를 조회해 봅니다.

```{r}
heartfailure_test %>% 
  tibble::as_tibble()
```

training 데이터셋으로 정의한 레시피를 test 데이터셋에 적용하여 조리합니다. 결과를 보면, 수치형 변수가 표준화되었음을 알 수 있습니다.

```{r}
heartfailure_recipe %>% 
  prep() %>% 
  bake(new_data = heartfailure_test)
```

tidymodels 패키지의 recipe는 똑똑합니다. 조리가 된 test 데이터셋 결과에서 target 변수의 불균형을 검사해 보았습니다. 

training 데이터셋의 조리에서는 불균형이 해소되었었는데, test 데이터셋의 조리에서는 원 데이터 속성 그대로 입니다. 왜냐하면 imbalanced 데이터의 이슈해결의 대상은 training 데이터셋에만 국한된 것이니까요.

```{r}
# 원 데이터의 target 변수의 분포
heartfailure_test %>% 
  count(death_event) %>% 
  mutate(pct = round(n / sum(n) * 100, 2))    

# 조리된 데이터의 target 변수의 분포
heartfailure_recipe %>% 
  prep() %>% 
  bake(new_data = heartfailure_test) %>% 
  count(death_event) %>% 
  mutate(pct = round(n / sum(n) * 100, 2))    
```

### Workflow

위키백과에서는 workflow를 다음과 같이 정의합니다.

"워크플로(영어: workflow)는 작업 절차를 통한 정보 또는 업무의 이동을 의미하며, 작업 흐름이라고도 부른다. 더 자세히 말해, 워크플로는 작업 절차의 운영적 측면이다. 업무들이 어떻게 구성되고, 누가 수행하며, 순서가 어떻게 되며, 어떻게 동기화를 시킬지, 업무를 지원하기 위한 정보가 어떻게 흐르는지 그리고 업무가 어떻게 추적되는지이다."

tidymodels 패키지에서도 workflow를 지원합니다. 이 기능으로 ML 개발 작업과 운영 작업이 좀더 수월해 집니다.


#### 워크플로우 정의

다음은 기 정의된 logistic regression 모델 정의와 앞에서 정의한 레시피를 묶어서 워크플로우를 만듧니다.

- `workflows` 패키지의 `workflow()` 함수로 워크플로우를 만들고, 
- `add_model()` 함수로 적합할 ML 모델 알고리즘과
- `add_recipe()` 함수로 데이터 조리 레시피를 적용합니다.

```{r}
# 워크플로우 정의하기
heartfailure_wf <- workflow() %>% 
  add_model(logistic_model) %>% 
  add_recipe(heartfailure_recipe)

# 워크플로우 내용
heartfailure_wf
```

#### 워크플로우 기반 모델 적합

`tune` 패키지의 `last_fit()` 함수가 워크플로우를 실행해서 모델을 적합합니다. 

이때 `split` 인수에서 정의한 "initial_split" 객체를 참고하여, traing 데이터 셋으로 모델을 만들고, test 데이터셋으로 예측한 결과로 성능평가 지표도 생성합니다. 

```{r}
# 워크플로우 기반 모델 적합
heartfailure_fit <- heartfailure_wf %>% 
  last_fit(split = heartfailure_split)

# 적합된 결과로서의 "last_fit" 객체
heartfailure_fit
```

성능평가 지표를 조회하기 위해서는 `tune` 패키지의 `collect_metrics()` 함수를 사용합니다. 기본설정으로는 성능평가 지표는 `accuracy`와 `roc_auc`가 계산됩니다. 각각 `Accuracy`와 `Area under the receiver operator curve`입니다.

```{r}
heartfailure_fit %>% 
  collect_metrics()
```


### Cross Validation

모델의 과적합을 방지하기 위해서 `N-Fold Cross-Validation`를 수행할 수 있습니다.

#### Cross Validation 정의

`rsample` 패키지의 `vfold_cv()` 함수를 사용합니다. 다음은 `10-Fold Cross-Validation`을 정의합니다.

```{r}
set.seed(12345)

# `10-Fold Cross-Validation` 정의
heartfailure_fold <- heartfailure_train %>% 
  vfold_cv(v = 10, strata = death_event)

# `10-Fold Cross-Validation` 내용
heartfailure_fold
```

#### Cross Validation 적용 모델링

이번에는 `yardstick` 패키지의 `metric_set()` 함수로 평가 메트릭을 추가로 정의합니다. 그리고 `tune` 패키지의 `fit_resamples()` 함수로 Cross Validation을 수행하면서 모델을 적합합니다.

```{r}
# 모델 검증을 위한 메트릭 정의
heartfailure_metrics <- metric_set(
  roc_auc, sens, spec, f_meas
)

# 워크플로우에 Cross Validation 적용 모델링
heartfailure_fit_rs <- heartfailure_wf %>% 
  fit_resamples(
    resamples = heartfailure_fold,
    metrics = heartfailure_metrics,
    control = control_resamples(save_pred = TRUE)
  )
```


`10-Fold Cross-Validation`의 성능 지표는 다음과 같습니다. 이들 성능 지표는 10번 수행 결과의 평균값들입니다.

```{r}
# 성능 평가 메트릭 조회
heartfailure_fit_rs %>% 
  collect_metrics()
```


그리고, `10-Fold Cross-Validation`의 Confusion Matrix도 10번 수행 결과의 평균입니다. 그렇기 때문에 각 셀의 값이 작습니다.

```{r}
# Confusion Matrix
heartfailure_fit_rs %>% 
  conf_mat_resampled(tidy = FALSE)
```

Confusion Matrix를 앞서 만들었던 모델과 비교하기 위해서 상대비율로 계산합니다.


```{r}
# 상대 비율로 계산한 Confusion Matrix
heartfailure_fit_rs %>% 
  conf_mat_resampled(tidy = FALSE) %>% 
  "$"(table) %>% 
  prop.table()
```


앞서 처음 만들었던 모델의 Confusion Matrix의 상대비율입니다. True-Positive가 증가한 것은 이번 모델은 target 변수의 불균형 클래스를 보정했기 때문으로 추측됩니다.

```{r}
cmat %>% 
  "$"(table) %>% 
  prop.table()
```

### Hyper-Parameters 튜닝

logistic regression 모델의 경우에는 Hyper-Parameters 튜닝이 필요없지만, 최근에 사용되는 모델들은 Hyper-Parameters 튜닝이 유용한 경우가 많습니다.


#### Lasso 모형 정의

Hyper-Parameters 튜닝의 설명을 위해서 Lasso regression 모형을 적합하려 합니다.

Lasso regression 모형은 `parsnip` 패키지의 `logistic_reg()` 함수의 `mixture` 인수를 1로 지정하면 됩니다. 즉 알파의 값이 1입니다. 그리고 `penalty` 파라미터는 Hyper-Parameters 튜닝을 위해서 임시로 `tune::tune()`로 정의해 줍니다.

```{r}
lasso_model <- parsnip::logistic_reg(penalty = tune::tune(), mixture = 1) %>% 
  parsnip::set_engine("glmnet") %>% 
  parsnip::set_mode("classification")
```

#### Recipe 수정

Lasso regression 모형은 명목형 변수를 지원하지 않기 때문에 명목형 변수를 One-Hot 인코딩 방법으로 가변수 처리합니다. 기존 레시피에 `step_dummy()` 함수를 적용합하면 됩니다.

```{r}
# 명목형 변수의 가변수화
lasso_recipe <- heartfailure_recipe %>% 
  step_dummy(all_nominal(), -all_outcomes())

# 변경된 레시피
lasso_recipe
```


#### 워크플로우 정의

워크플로우를 재정의합니다.

```{r}
# Lasso 모형워크플로우 정의하기
lasso_wf <- workflows::workflow() %>% 
  workflows::add_model(lasso_model) %>% 
  workflows::add_recipe(lasso_recipe)

# 워크플로우 내용
lasso_wf
```


#### Hyper-Parameters 튜닝

파라미터 penalty를 위해서 30개의 값으로 그리드를 정의합니다. `tune` 패키지의 `tune_grid()` 함수로 30개의 penalty 값에 대해서 모형을 적합합니다.

```{r}
lasso_grid <- tibble::tibble(penalty = 10^seq(-2, -1, length.out = 30))

lasso_tune_grid <- lasso_wf %>%
  tune::tune_grid(
    resamples = heartfailure_fold, 
    grid = lasso_grid, 
    control = tune::control_grid(verbose = FALSE, save_pred = TRUE), 
    metrics = yardstick::metric_set(
      accuracy, bal_accuracy, detection_prevalence, f_meas, j_index, kap, mcc, 
      npv, ppv, precision, recall, sensitivity, specificity))
```

`collect_metrics()` 함수는 30개의 penalty 값별로 계산한 성능평가 지표를 조회합니다. accuracy부터 specificity까지 13개의 성능지표에 대한 추정값을 조회할 수 있습니다.

10-Fold CV로 30개 penalty에 대해 30개의 모델이 적합되고 각각 13개의 성능지표를 계산하였으므로, 390개의 지표가 계산됩니다.

```{r}
lasso_tune_grid %>%
  tune::collect_metrics()
```

30개의 모델 중에서 하나의 모델을 선택해야 합니다. 여기서는 F1값이 가장 좋은 모델을 선정하겠습니다. 다음과 같은 과정을 거쳐서 최종 워크플로우를 생성합니다.

```{r}
best_metric <- "f_meas"

best_model <- lasso_tune_grid %>%
  tune::select_best(best_metric)

final_wf <- lasso_wf %>%
  tune::finalize_workflow(best_model)
```

이 워크플로우로 최종 모델에서의 개별 변수의 계수를 다음처럼 계산할 수 있습니다.

```{r}
coefs <- final_wf %>%
  fit(data = heartfailure_train) %>% 
  tidy() %>%
  filter(!term %in% "(Intercept)") %>%
  group_by(estimate > 0) %>%
  top_n(10, abs(estimate)) %>%
  ungroup() %>%
  mutate(term = forcats::fct_reorder(term, estimate)) %>%
  filter(estimate != 0)  

coefs
```

그리고 이 계수를 시각화하면 모델을 좀더 쉽게 이해할 수 있습니다.

수축치 심장에서 나가는 혈액의 비율인 `ejection_fraction`이 심부전증 환자의 사망에 영향이 크고, 반대로 혈중 크레아티닌 수치인 `creatinine`가 생존에 미치는 영향이 큽니다.

```{r, out.width="65%", fig.width=6, fig.height=5, dpi=250}
library(ggplot2)

coefs %>% 
  ggplot(aes(x = term, y = estimate, fill = `estimate > 0`)) + 
  geom_col(alpha = 0.8, show.legend = FALSE) + 
  coord_flip() + 
  labs(x = NULL, title = "death_event 예측에 영향을 주는 모델의 변수들") + 
  theme_minimal(base_family = "NanumSquare")
```

#### 예측

다시 돌아와서 최종 워크플로우로 테스트 데이터셋을 적용 예측하고, Confusion Matrix를 계산해봅니다.

`tune` 패키지의 `last_fit()` 함수로 마지막 모델을 적합합니다. 여기서는 training 데이터셋이 사용됩니다. 그리고 `collect_predictions()` 함수로 test 데이터셋에 대해서 `death_event`를 예측해 봅니다.


```{r}
# 최종 모형 적합
final_fit <- final_wf %>%
  tune::last_fit(split = heartfailure_split)

# test 데이터셋의 target variable 예측
pred <- final_fit %>%
  tune::collect_predictions()

# 예측된 결과
pred
```

마지막으로 예측된 값으로 Confusion Matrix를 계산합니다.

```{r}
# Confusion Matrix 계산
cmat <- pred %>%
  yardstick::conf_mat(truth = death_event, .pred_class)

cmat
```

### 마무리

이상으로 가겹게 tidymodels 프레임워크를 이용하여 Binary Classification을 수행해 보았습니다.

레시피와 워크플로우라는 개념이 생소할 수 있겠으나, 익숙해지면 모델을 만들고 유지보수하는 작업이 좀 더 수월해질 수 있으니, 이 소개글이 여러분의 새로운 도전에 길잡이가 되었으면 좋겠습니다.


